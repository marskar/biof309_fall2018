{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/img/pandas.png\" alt=\"Operations Across Axes\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Pandas](http://pandas.pydata.org/) - Python Data Analysis Library\n",
    "---\n",
    "## I shamelessly picked from these folks:\n",
    " - [Daniel Chen - Pandas for Data Analysis](https://www.youtube.com/watch?v=oGzU688xCUs)\n",
    " - [Jeff Delaney - 19 Essential Snippets in Pandas](https://jeffdelaney.me/blog/useful-snippets-in-pandas/)\n",
    " - [Burke Squires - Intro to Data Analysis with Python](https://github.com/burkesquires/python_biologist/tree/master/05_python_data_analysis)\n",
    "\n",
    "\n",
    "## General Outline:\n",
    "- What is Pandas all about?\n",
    "- Brief intro to Pandas objects and syntax\n",
    "- NumPy dataframe, show the basics\n",
    "- Import gapminder dataset, interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Jupyter Notebook Shortcuts](http://maxmelnick.com/2016/04/19/python-beginner-tips-and-tricks.html)\n",
    "- documentation:\n",
    "```python\n",
    "type?\n",
    "```\n",
    "- check function arguments using: shift + tab\n",
    "- run current cell/block: shift + enter \n",
    "- insert cell above: esc + a\n",
    "- delete cell: esc (hold) + d + d (double tap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/img/python-scientific-ecosystem.png\" alt=\"Python Scientific Ecosystem\" />\n",
    "\n",
    "## [Legend has it...](https://qz.com/1126615/the-story-of-the-most-important-tool-in-data-science/ )\n",
    "Pandas was develped by Wes McKinney (from Akron, Ohio!!!).  Math guy from MIT that went into finance, found that the problem with hedge fund management was dealing with the data (sourcing new data, merging it with the old, and cleaning it all up to optimize the input).  He got bummed out with Excel and R but was smitten with Python, though he realized there was no robust package for data analysis.  So he built Pandas in 2008 and released the project to the public in 2009.\n",
    "\n",
    "Here's where it get's crazy, he left the world if finance to pursue a PhD in statistics at Duke, thus dropping Pandas development.  During that period he realized Python as a language could explode as a statistical computing language, it had the potential, but was still missing robust packages.  So he dropped out to push Pandas to become the a cornerstone of the Python scientific ecosystem.\n",
    "\n",
    "And he put all his tips and tricks for Pandas into a book: [Python for Data Data Analysis](https://github.com/wesm/pydata-book)\n",
    "\n",
    "## What is Pandas?\n",
    "\n",
    "\"It enables people to analyze and work with data who are not expert computer scientists.  You still have to write code, but it's making the code intuitive and accessible.  It helps people move beyond just using Excel for data analysis.\" ~Wes\n",
    "\n",
    "- The go-to data analysis library for Python\n",
    "    - Import and wrangle your raw data\n",
    "    - Manipulate and visualize\n",
    "- Allows for mixed data types in the same array\n",
    "\n",
    "### The DataFrame is your friend!\n",
    "- Two primary object types used in Pandas:\n",
    "    - DataFrames - like an Excel spreadsheet\n",
    "    - Series - like a single column in a spreadsheet\n",
    "- DataFrames are the primary object used in Pandas (it's like an Excel sheet)\n",
    "- Each DataFrame has:\n",
    "    - columns: the variables being measured\n",
    "    - rows: the observations being made\n",
    "    - index: maintains the order of the rows\n",
    "- Executing an action across an axis\n",
    "    - Axis 0 = default, 'index', perform action along index (performing in each column)\n",
    "    - Axis 1 = 'columns', perform action along columns (performing for each row)\n",
    "    - This is kinda wonky, but you can think of it like this:\n",
    "        - Axis 0 will give me mean of each column\n",
    "        - Axis 1 will give me the mean of each row\n",
    "\n",
    "<img src=\"files/img/dataframe.jpg\" alt=\"Pandas DataFrame\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "---\n",
    "You can import LOADS of different file types into Pandas as a DataFrame.  The most common that you may run into would be .csv and Excel files, but we're going to start by using a NumPy array as the input for our DataFrame.\n",
    "\n",
    "## Create A NumPy Array Of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check numpy version\n",
    "import numpy as np\n",
    "print('NumPy version:',np.version.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a 4x100 numpy ndarray using numpy.random.randint()\n",
    "# be sure to set the seed to 0 if you want to replicate the results\n",
    "np.random.seed(0)\n",
    "array = np.random.randint(0,100,size=(20,4))\n",
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the array and the type\n",
    "type(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas library\n",
    "import pandas as pd\n",
    "print('Pandas version:', pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# checkout the documentation\n",
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Pandas DataFrame from the NumPy ndarray\n",
    "df = pd.DataFrame(data=array, index=None, columns=None, dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring A DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check out what the dataframe looks like\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can also use the len() function to get the number or rows/observations\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a concise summary of the DataFrame with .info()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view brief descriptive stats of the DataFrame\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the top 5 rows\n",
    "# you can input how many rows you want, default is 5\n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the bottom 5 rows\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a sample of random rows/observations\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating DataFrame Columns (Variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view current columns \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send current column names to a list\n",
    "cols = df.columns.tolist()\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column names\n",
    "# create a list of new column names (same length as columns)\n",
    "cols = ['a', 'b', 'c', 'd']\n",
    "\n",
    "# set \"df.columns\" to the new list of names\n",
    "df.columns = cols\n",
    "\n",
    "# check the change by viewing the head of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an individual column\n",
    "df['a']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice that a single column is a \"Series\" object in Pandas\n",
    "type(df['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert a new column and put a string in each cell\n",
    "df['new_column'] = 'cheese'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffling column positions\n",
    "\n",
    "# set current column order to a list object\n",
    "cols = df.columns.tolist()\n",
    "print('Starting column order:', cols)\n",
    "\n",
    "# manipulate column names as a list object\n",
    "# reverse column order\n",
    "rev_order = cols[::-1]\n",
    "print('Reverse column order:', rev_order)\n",
    "\n",
    "# move last column to first\n",
    "new_order = cols[-1:] + cols[:-1]\n",
    "print('Last to first order:', new_order)\n",
    "\n",
    "# set the column order (creates new dataframe)\n",
    "df = df[new_order]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete a column\n",
    "del df['new_column']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternate way to delete column (or row), axis numbers are reversed\n",
    "\n",
    "# save the column to add back later\n",
    "a = df['a']\n",
    "\n",
    "# use drop() to remove column\n",
    "df.drop(['a'], axis=1) # does this really delete the column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recheck to see if column 'a' was dropped\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop column 'a' properly\n",
    "df2 = df.drop(['a'], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but we still have the original DataFrame with 4 columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Values from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas has basic arithmetic functions built-in\n",
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Axis Key\n",
    "- 0 == Calculate statistic for each column (across rows)\n",
    "- 1 == Calculate statistic for each row (across columns)\n",
    "  \n",
    "<img src=\"files/img/python-operations-across-axes.svg\" alt=\"Operations Across Axes\" />\n",
    "\n",
    "* The axis key is reversed when using the drop() function to remove columns/rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the axis to apply functions across rows or down columns\n",
    "df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the sum of specific columns\n",
    "df[['a', 'b']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column called \"sum\" containint the sum of each row\n",
    "df['sum'] = df.sum(axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does the sum stay updated?\n",
    "# insert a new row of random integers\n",
    "df['e'] = np.random.randint(0,100, size=df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Exercise\n",
    "1. Make an object titled \"df3\" that is a copy of \"df\"\n",
    "2. Add a column to \"df3\" that expresses the [mean](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.mean.html) of the values in columns a, b, c, and d across each row \n",
    "    * What axis refers to calculations across a row?\n",
    "3. Make an object titled \"df4\" that is a copy of \"df3\" and delete column \"c\" from df4 \n",
    "    * Do the values in the \"mean\" column change?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make an object titled \"df3\" that is a copy of \"df\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a mean column in df3 that calculates the mean across each row\n",
    "# be sure to exclue the sum value from the mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a copy of df3 named df4, delete column \"c\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Combining DataFrames\n",
    "Before getting into the manipulation of DataFrame rows it helps to understand a bit more about index values and combined dataframes\n",
    "<img src=\"files/img/concat_axis0.png\" alt=\"concat axis0\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two new DataFrames from NumPy values\n",
    "df_index1 = pd.DataFrame(np.random.randint(0,100, size = (50,4)), \n",
    "                         columns = ['a', 'b', 'c', 'd'])\n",
    "df_index2 = pd.DataFrame(np.random.randint(0,100, size = (50,4)), \n",
    "                         columns = ['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use pd.concat() to combine the two DataFrames by stacking vertically (axis=0)\n",
    "cat_df = pd.concat([df_index1, df_index2], axis=0) # what happens if the axis is 1?\n",
    "cat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# check the index\n",
    "cat_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset_index() will generate a column with the old index\n",
    "# use this function when you want to reset the order of the index\n",
    "reset = cat_df.reset_index()\n",
    "# reset = cat_df.reset_index(drop=True) # use this to drop the new column with old index\n",
    "reset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating DataFrame Rows (Observations)\n",
    "Two important functions to introduce here are loc() and iloc()\n",
    "- loc[ ] - accesses the index based on the value\n",
    "- iloc[ ] - accesses the index based on the position.  \n",
    "You may come across ix[ ] to select rows, but this function has depreciated \n",
    "\n",
    "Tips for specifying indexers:\n",
    "- series.loc[indexer]\n",
    "- dataframe.loc[row_indexer, column_indexer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We're going back to the concatenated Dataframe that was NOT reindexed\n",
    "\n",
    "# select a row based on the index value using loc\n",
    "cat_df.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compare this with selecting a row using iloc\n",
    "cat_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just for giggles, try using ix for the same row\n",
    "cat_df.ix[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# changing all the values in a specific row\n",
    "cat_df.iloc[0] = [44, 45, 46, 47]\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change a single value in a row\n",
    "cat_df.loc[0,'d'] = 50\n",
    "cat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a row using loc[]\n",
    "cat_df.loc[len(df)] = [1,2,3,4]\n",
    "cat_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# delete the row that was just added using drop()\n",
    "new = cat_df.drop(100)\n",
    "new.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting A DataFrame\n",
    "If you want to save your work you can [pickle](https://ianlondon.github.io/blog/pickling-basics/) the DataFrame or you could export it as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the \"new\" DataFrame as a .csv file, can export in multiple file types\n",
    "new.to_csv('my_dataframe.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots\n",
    "In general, the [Matplotlib](https://matplotlib.org/) library is the go-to for plots and figures, but Pandas has a plot() function that uses matplotlib to generate basic visualizaitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can use the Pandas plot() function to return a matplotlib.axes.AxesSubplot object\n",
    "plot = reset.plot(x=None, y=None, kind='line')\n",
    "plot.set_xlabel('x label')\n",
    "plot.set_ylabel('y label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# how to save a figure\n",
    "\n",
    "# save the figure by using get_figure() to extract the plot as \n",
    "# a matplotlib.figure.Figure object\n",
    "fig = plot.get_figure()\n",
    "fig.savefig('figure.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "* Create a bar plot for the first 20 values in column \"a\" in the \"reset\" DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bar = reset['a'][:20].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working With Heterogeneous Data\n",
    "---\n",
    "## Import a .csv as a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a .csv file to a DataFrame\n",
    "df = pd.read_csv('data/gapminder.tsv', \n",
    "                 sep='\\t', # the delimiter in the file\n",
    "                 header='infer', # row with names of the columns \n",
    "                 names=None, # change the names of the columns\n",
    "                 index_col=None, # column to use for the row index\n",
    "                 usecols=None) # what columns to use\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip-down column names\n",
    "df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('-','_')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take A Glance At The DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shape, columns, values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Techniques To Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting\n",
    "# Why not sort the df by year in ascending order\n",
    "df = df.sort_values('year', axis=0, ascending=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique Values\n",
    "# Get a list of the countries represented using unique()\n",
    "countries = df.country.unique()\n",
    "len(countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about continents?\n",
    "df.continent.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby\n",
    "# How would I get a list of the countries that fall within \"Oceania\"?\n",
    "df.groupby('continent')['country'].unique()['Oceania']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nunique()\n",
    "# How many countries are represented by each continent?\n",
    "df.groupby('continent')['country'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about a dictionary containing all the countries for each continent?\n",
    "conts = df.groupby('continent')['country'].unique()\n",
    "cont_dict = conts.to_dict()\n",
    "cont_dict['Africa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cont_dict['Africa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Using Conditional Logic\n",
    "# What if we just want a DataFrame of all the African countries?\n",
    "africa = df[df['continent'] == 'Africa']\n",
    "africa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reset the index\n",
    "africa = africa.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the new africa df\n",
    "africa.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new series with the mean gdp per cap for each country in africa\n",
    "mean_gdp_country = africa.groupby('country')['gdp_per_cap'].mean()\n",
    "mean_gdp_country.plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a boxplot\n",
    "mean_gdp_country.plot(kind='box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter further with conditional logic\n",
    "# create a DataFrame that cuts down the outliers\n",
    "filt_africa = africa[africa.gdp_per_cap < 2500]\n",
    "plot = filt_africa['gdp_per_cap'].plot(kind = 'hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply()\n",
    "# create a category/bins and apply to gdp per cap\n",
    "\n",
    "# start with a function\n",
    "def func(x):\n",
    "    if x <=500:\n",
    "        return 'low'\n",
    "    elif 500< x <1750:\n",
    "        return 'mid'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "# apply the new function to each row in the DataFrame\n",
    "africa['gdp_category'] = africa['gdp_per_cap'].apply(func)\n",
    "africa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we could also use the cut() function\n",
    "bins = [0,500, 2750, 70000]\n",
    "names = ['low', 'mid', 'high']\n",
    "africa['new_categories'] = pd.cut(africa.loc[:,'gdp_per_cap'], bins, labels=names)\n",
    "africa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc.\n",
    "---\n",
    "## Create a Pandas DataFrame from a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dictionary object\n",
    "my_dict = {'a':['cheese', 'dog', 'goat', '4h'], 'b':['lush','planet', '2017', 'la trance'] }\n",
    "\n",
    "# create a pandas DataFrame from a dictionary\n",
    "df = pd.DataFrame(my_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
